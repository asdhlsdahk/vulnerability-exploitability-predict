import pandas as pd
from sklearn.model_selection import train_test_split
import lightgbm as lgb
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import accuracy_score
# from sklearn.preprocessing import Imputer
from sklearn.impute import SimpleImputer
from sklearn.metrics import roc_auc_score, accuracy_score
import numpy as np
# 1.读文件
import pickle
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import precision_recall_curve

from sklearn.metrics import classification_report
# import pydot
pickle_file = open("trainhe.pkl","rb")
pickle_file2 = open("labelhe.pkl","rb")
x_train = pickle.load(pickle_file)
print(x_train)
y_train = pickle.load(pickle_file2)
print(y_train)
# 2.切分数据输入：特征 输出：预测目标变量
# y = data.SalePrice
# X = data.drop([SalePrice], axis=1).select_dtypes(exclude=[object])
#
# # 3.切分训练集、测试集,切分比例7.5 : 2.5
train_X, test_X, train_y, test_y = train_test_split(x_train, y_train, test_size=0.2)
lgb_train = lgb.Dataset(train_X, train_y)
lgb_eval = lgb.Dataset(test_X, test_y, reference=lgb_train)
print("kaishixunlian")
evals_result = {}  #记录训练结果所用
# # 6.参数
params = {
    'task': 'train',
    'boosting_type': 'gbdt',  # 设置提升类型
    'objective': 'regression',  # 目标函数
    'metric': {'l2', 'auc','f1-score'},  # 评估函数
    'num_leaves': 32,  # 叶子节点数
    'learning_rate': 0.15,  # 学习速率
    'feature_fraction': 0.9,  # 建树的特征选择比例
    'bagging_fraction': 0.8,  # 建树的样本采样比例
    'bagging_freq': 5,  # k 意味着每 k 次迭代执行bagging
    'verbose': 1,  # <0 显示致命的, =0 显示错误 (警告), >0 显示信息
    'class_weight': {'balanced', None}
}

# # 7.调用LightGBM模型，使用训练集数据进行训练（拟合）
# # Add verbosity=2 to print messages while running boosting
my_model = lgb.train(params, lgb_train, num_boost_round=50, valid_sets=lgb_eval, early_stopping_rounds=5,evals_result=evals_result, verbose_eval=10)
my_model.save_model('model.txt')

with open('model.pickle', 'wb') as f:
    pickle.dump(my_model, f)

# # 8.使用模型对测试集数据进行预测
predictions = my_model.predict(test_X, num_iteration=my_model.best_iteration)
print(my_model.best_score)
# my_model.fit(train_X, train_y)
precisions, recalls, thresholds = precision_recall_curve(y_train, my_model.predict(x_train))
# precisions = cross_val_score(my_model, train_X, train_y, cv=5, scoring='precision')
print('精确率：', np.mean(precisions), precisions)
# recalls = cross_val_score(my_model, train_X, train_y, cv=5, scoring='recall')
print('召回率：', np.mean(recalls), recalls)
# f1s = cross_val_score(my_model, train_X, train_y, cv=5, scoring='f1')
# print('综合评价指标：', np.mean(f1s), f1s)
print('----------------------------------------------------')
# # 9.对模型的预测结果进行评判（平均绝对误差）
print("Mean Absolute Error : " + str(mean_absolute_error(test_y, predictions)))
# print(my_model.params)
acc = np.zeros(757)
for i in range(0, 757):
    acc[i] = test_y[i][0]

print(type(predictions[0]))
print(type(acc[0]))
from sklearn.metrics import classification_report,accuracy_score, auc, confusion_matrix, f1_score, precision_score, recall_score,roc_curve
print(format(accuracy_score(acc, predictions.round())))


mean = float('%.4f' % np.mean(predictions == test_y))
recall_str = classification_report(acc, predictions.round())
# y_score = my_model.predict_proba(test_X)
y_score = np.zeros(shape=(757, 2))
for i in range(0,757):
    pre2 = 1 - predictions[i]
    y_score[i][0] = pre2
    y_score[i][1] = predictions[i]
fpr, tpr, thresholds = roc_curve(test_y, y_score[:, 1])
# names_list = (iris_df.columns.difference(["response"])).tolist()  # 分类模型维度列表
color_list = ['r', 'c', 'b', 'g']  # 颜色列表
plt.figure(figsize=(10, 5))  # 创建画布
# 子网格1：ROC曲线
plt.subplot(2, 2, 1)  # 第一个子网格
plt.plot(fpr, tpr, label='ROC')  # 画出ROC曲线
plt.plot([0, 1], [0, 1], linestyle='--', color='k', label='random chance')  # 画出随机状态下的准确率线
plt.title('ROC')  # 子网格标题
plt.xlabel('false positive rate')  # X轴标题
plt.ylabel('true positive rate')  # y轴标题
plt.legend(loc=0)

# 子网格2：指标重要性
# feature_importance = my_model.feature_importances_  # 获得指标重要性
plt.subplot(2, 2, 2)  # 第二个子网格
# plt.bar(np.arange(feature_importance.shape[0]), feature_importance, tick_label=names_list,
#         color=color_list)  # 画出条形图
plt.title('feature importance')  # 子网格标题
plt.xlabel('features')  # x轴标题
plt.ylabel('importance')  # y轴标题
plt.suptitle('classification result')  # 图形总标题
plt.savefig("E:examples.png")
plt.show()
# 子网格3：
plt.subplot(2, 2, 3)  # 第二个子网格
plt.axis('off')
plt.title('mean:' + str(mean), loc='center')  # 子网格标题

plt.subplot(2, 2, 4)  # 第二个子网格
plt.axis('off')
plt.title(recall_str, loc='right')
fig = plt.gcf()
# 自动调整绘图区的大小及间距，在cmd窗口调用脚本时绘制图位置会错乱
fig.tight_layout()
fig.savefig("E:examples.png")
plt.show()
plt.close()

